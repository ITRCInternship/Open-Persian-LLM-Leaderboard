# Researching on classifying Persian texts (tweets/comments) with LLM and their results.
# چکیده

   با گسترش شبکه‌های اجتماعی، تولید محتوای متنی در زبان فارسی به‌ویژه در قالب نظرات و توییت‌ها افزایش یافته است. طبقه‌بندی خودکار این متون می‌تواند نقش مهمی در تحلیل احساسات، شناسایی محتوای توهین‌آمیز و تشخیص اسپم ایفا کند. در این پژوهش، به بررسی عملکرد مدل‌های زبانی بزرگ (LLM) در طبقه‌بندی متون فارسی می‌پردازیم. 
  مدل‌هایی مثل ParsBERT، XLM-R و mBERT  به‌صورت دقیق ارزیابی و مقایسه شده‌اند. نتایج نشان می‌دهد که مدل‌های زبان‌بومی‌شده مانند ParsBERT نسبت به مدل‌های چندزبانه دقت بالاتری در درک متون غیررسمی فارسی دارند.
  
  # مقدمه:
  
  با رشد روزافزون استفاده از شبکه‌های اجتماعی و پیام‌رسان‌ها، حجم عظیمی از محتوای متنی به زبان فارسی به‌صورت روزانه تولید می‌شود. تحلیل این داده‌ها برای اهدافی همچون تحلیل احساسات کاربران، شناسایی نظرات مخرب، تشخیص نظرات جعلی یا تبلیغاتی، و دسته‌بندی موضوعی اهمیت بسیاری یافته است. از طرفی، زبان فارسی به دلیل ساختار خاص خود، چالش‌هایی برای پردازش زبان طبیعی (NLP) ایجاد می‌کند.
  مدل‌های زبانی بزرگ (Large Language Models) یا LLM) مانند BERT و GPT تحولی عظیم در حوزه پردازش زبان طبیعی ایجاد کرده‌اند. با آموزش این مدل‌ها روی داده‌های عظیم و استفاده از معماری‌های عمیق، امکان فهم بهتر ساختار و معنای جملات فراهم شده است. در سال‌های اخیر، مدل‌هایی خاص برای زبان فارسی نیز توسعه یافته‌اند که از مهم‌ترین آن‌ها می‌توان به ParsBERT اشاره کرد.
  در این تحقیق، هدف ما بررسی و مقایسه کارایی مدل‌های LLM در طبقه‌بندی متون فارسی است. تمرکز اصلی روی داده‌های شبکه‌های اجتماعی مانند توییتر و نظرات کاربران است که اغلب دارای لحن غیررسمی، نگارش متفاوت و واژگان عامیانه هستند. در سال‌های اخیر، استفاده از مدل‌های زبانی بزرگ (LLM) برای پردازش زبان طبیعی (NLP) در زبان فارسی، رشد چشم‌گیری داشته است. در این بخش، مهم‌ترین مدل‌های زبانی مورد استفاده در طبقه‌بندی متون فارسی بررسی می‌شوند.

   
   #  1)	ParsBERT


•	توسعه‌دهنده: دانشگاه علم و صنعت ایران (2020)

•	پایه: معماری BERT

•	ویژگی: آموزش‌دیده بر بیش از 3 میلیارد کلمه از منابع فارسی (ویکی‌پدیا، اخبار، کتاب‌ها)
•	کاربرد: تحلیل احساسات، طبقه‌بندی متون، پاسخ‌ به پرسش‌ها
•	مزیت: عملکرد بهتر از mBERT در داده‌های فارسی
در پژوهش "ParsBERT: Transformer-based Model for Persian Language Understanding" نشان داده شد که این مدل در اکثر تسک‌های NLP فارسی بهتر از مدل‌های چندزبانه عمل می‌کند.



# 2)	mBERT (Multilingual BERT)

•	توسعه‌دهنده: Google 

•	زبان‌ها 104: زبان از جمله فارسی

•	ویژگی: آموزش دیده به‌صورت چندزبانه بدون تنظیم خاص برای زبان فارسی

•	مزیت: مناسب برای زبان‌هایی با داده کم

•	نقص: عملکرد ضعیف‌تر از ParsBERT در فارسی‌های غیررسمی و عامیانه



# 3)	XLM-RoBERTa
•	توسعه‌دهنده Facebook AI (Meta):

•	زبان‌ها: چندزبانه با عملکرد بهتر از mBERT در زبان‌های کم‌منبع

•	ویژگی: مبتنی بر RoBERTa و دارای قدرت تعمیم بهتر

•	در فارسی: نسبتاً بهتر از mBERT، ولی هنوز از ParsBERT ضعیف‌تر




# 4)	GPT-3 / GPT-4 (OpenAI) 

•ویژگی: مدل‌های مولد با توانایی فوق‌العاده در درک زبان

•	محدودیت: آموزش‌ندیده مستقیماً روی داده‌های فارسی؛ نیاز به ترجمه برای استفاده دقیق

•	روش پیشنهادی: Prompting همراه با ترجمه فارسی به انگلیسی

•	نتیجه: دقت قابل قبول ولی محدودیت در فهم ظرافت‌های زبانی فارسی






# 5)	ParsiGPT ParsiGPT و Ghazal مدل‌های GPT فارسی

•	توسعه‌دهنده: آزمایشگاه NLP دانشگاه تهران

•	معماری: مشابه GPT اما با داده‌های فارسی

•	کاربرد: پاسخ به پرسش، تولید متن، طبقه‌بندی ساده

•	محدودیت: مقیاس کوچک‌تر، داده آموزشی محدود، در مرحله آزمایشی

# مقایسه مدل‌های زبانی برای فارسی

در جدول زیر ویژگی‌های برخی مدل‌های زبانی مناسب برای پردازش زبان فارسی مقایسه شده‌اند:




# داده‌ها و پیش‌پردازش

## مجموعه داده

از دیتاست توییت‌های فارسی شامل سه دسته برچسب‌خورده استفاده شده است:

•	Normal  عادی

•	 Offensive توهین‌آمیز

•	 Hate نفرت‌پراکن




# مراحل پاک‌سازی

•	حذف لینک‌ها، کاراکترهای خاص، ایموجی‌ها و اعداد

•	نرمال‌سازی کلمات


•	توکن‌سازی با استفاده از Tokenizer مدل مورد نظر مثلاً ParsBERT 




                                                                                                                      
                                                                                                                               




# Open-Persian-LLM-Leaderboard


# 1.	Model = مدل

 نام مدل زبان بزرگ (مانند llama-3, gemma, qwen, aya و ...) که مورد ارزیابی قرار گرفته است.
 
✅ مقایسه بین مدل‌هاست، نه عددی.

________________________________________

# 2.	Precision = دقت عددی


نوع دقت عددی مورد استفاده برای اجرا یا آموزش مدل است، مثل bfloat16 یا float16. این بر حافظه و سرعت تأثیر دارد.

✅ تأثیر مستقیم بر عملکرد ندارد، بیشتر فنی است.

________________________________________
# 3.	Params (B) = تعداد پارامترها بر حسب میلیارد


 اندازه مدل بر حسب میلیارد پارامتر.
 
📌 مدل‌های بزرگ‌تر معمولاً توانمندترند ولی منابع بیشتری مصرف می‌کنند.

✅ بیشتر = توانمندتر، اما منابع بیشتر نیاز دارد

________________________________________

# 4.	Average Accuracy = دقت میانگین


میانگین دقت مدل در تمام بنچمارک‌هایی که در جدول آمده است.

✅ بیشتر بهتر است.

________________________________________

# 5.	Part Multiple Choice

درصد موفقیت مدل در بخش سؤالات چندگزینه‌ای (احتمالاً درک مطلب، منطق و اطلاعات عمومی.)

✅ بیشتر بهتر است.
________________________________________

# 6.	ARC Easy

عملکرد مدل در نسخه آسان آزمون ARC (AI2 Reasoning Challenge) که تست منطق و دانش ابتدایی است.

✅ بیشتر بهتر است.
________________________________________

# 7.	ARC Challenge

عملکرد در نسخه سخت‌تر ARC. این نسخه از مدل، استدلال پیچیده‌تری می‌طلبد.

✅ بیشتر بهتر است.

________________________________________

# 8.	MMLU Pro

میانگین دقت مدل در آزمون MMLU (Massive Multitask Language Understanding) با سطح حرفه‌ای، شامل موضوعاتی مانند ریاضیات، حقوق، پزشکی، و ...

✅ بیشتر بهتر است.
________________________________________

# 9.	AUT Multiple Choice Persian

عملکرد مدل در تست چندگزینه‌ای به زبان فارسی (احتمالاً آزمون از دانشگاه صنعتی امیرکبیر).

✅ بیشتر بهتر است.



# 1)meta-llama/Llama-3.3-70B-Instruct


•Precision = bfloat16

•Params (B) = 70.6

•Average Accuracy = 70.364

•Part Multiple Choice = 51.42

•ARC Easy = 95.4

•ARC Challenge = 89.93

•MMLU Pro = 43.67

•AUT Multiple Choice Persian = 71.4

### **جدول مشخصات مدل Meta-Llama-3.3-70B-Instruct**  

| **مشخصه**               | **مقدار**      |
|--------------------------|---------------|
| **نام مدل**             | Meta-Llama-3.3-70B-Instruct |
| **دقت محاسباتی**        | bfloat16      |
| **تعداد پارامترها (میلیارد)** | 70.6          |
| **دقت متوسط (Average Accuracy)** | 70.364%       |
| **سوالات چندگزینه‌ای عمومی** | 51.42%        |
| **ARC-Easy**            | 95.4%         |
| **ARC-Challenge**       | 89.93%        |
| **MMLU-Pro**            | 43.67%        |
| **AUT چندگزینه‌ای فارسی** | **71.4%**     |

---

### **توضیحات معیارها**  
- **ARC-Easy/Challenge**: ارزیابی درک و استدلال علمی (هرچه بالاتر، بهتر).  
- **MMLU-Pro**: سنجش دانش چندمنظوره (علوم، علوم انسانی و ...).  
- **AUT فارسی**: عملکرد در سوالات چندگزینه‌ای فارسی (مهم برای کاربران ایرانی).  

این مدل با **70.06B پارامتر** و دقت **bfloat16**، یکی از قوی‌ترین مدل‌های زبانی موجود است، با عملکرد قابل‌توجه در **پردازش زبان فارسی (71.4%)**. 


 # اطلاعات مدل 
**مدل هوش مصنوعی چندزبانه‌ی Llama 3.3 از متا**  

این مدل یک **چت‌بات پیشرفته** با ۷۰ میلیارد پارامتر است که هم **متن می‌گیرد** و هم **متن تولید می‌کند**. نسخه‌ی آموزش‌دیده‌ی این مدل مخصوص **چت چندزبانه** طراحی شده و در تست‌های استاندارد، از خیلی از مدل‌های رقیب (چه اوپن‌سورس و چه تجاری) بهتر عمل می‌کند.  

**سازنده:** شرکت متا (فیسبوک سابق)  

**چطوری کار می‌کند؟**  
- مدل Llama 3.3 بر اساس **ترنسفورمر** ساخته شده (همان معماری معروف ChatGPT).  
- با **آموزش انسانی** و **فیدبک کاربران** تنظیم شده تا هم **مفیدتر** باشد و هم **ایمن‌تر** (یعنی کمتر حرف‌های نامناسب بزند).  
- مثل یک انسان **پشت‌سرهم متن تولید می‌کند** (مدل "خودرگرسیو").  

به زبان ساده: **این مدل یه چت‌بات عالی است  که چندزبانه حرف می‌زند و سعی می‌کند مفید و بی‌خطر جواب بدهد!** 


# زبان‌های پشتیبانی شده:  
🇬🇧 **انگلیسی** (English)  
🇩🇪 **آلمانی** (German)  
🇫🇷 **فرانسوی** (French)  
🇮🇹 **ایتالیایی** (Italian)  
🇵🇹 **پرتغالی** (Portuguese)  
🇮🇳 **هندی** (Hindi)  
🇪🇸 **اسپانیایی** (Spanish)  
🇹🇭 **تایلندی** (Thai)  

این مدل می‌تواند به این ۸ زبان اصلی **به‌راحتی چت کند و متن تولید کند**.  🌍 

________________________________________





# 2) google/gemma-3-27b-it


•Precision = bfloat16

•Params (B) = 27.4

•Average Accuracy = 67.85

•Part Multiple Choice = 48.56

•ARC Easy = 95.69

•ARC Challenge = 90.6

•MMLU Pro = 40.1

•AUT Multiple Choice Persian = 64.3


### **جدول مشخصات مدل Google/Gemma-3-27B-IT**

| **مشخصه**               | **مقدار**      |
|--------------------------|---------------|
| **نام مدل**             | google/gemma-3-27b-it |
| **دقت محاسباتی**        | bfloat16      |
| **تعداد پارامترها (میلیارد)** | 27.4          |
| **دقت متوسط (Average Accuracy)** | 67.85%       |
| **سوالات چندگزینه‌ای عمومی** | 48.56%        |
| **ARC-Easy**            | 95.69%        |
| **ARC-Challenge**       | 90.6%         |
| **MMLU-Pro**            | 40.1%         |
| **AUT چندگزینه‌ای فارسی** | **64.3%**     |

---

### **توضیحات معیارها**
- **ARC-Easy/Challenge**: سنجش توانایی استدلال علمی (مقادیر بالاتر نشان‌دهنده عملکرد بهتر)
- **MMLU-Pro**: ارزیابی دانش چندرشته‌ای
- **AUT فارسی**: عملکرد در سوالات چندگزینه‌ای فارسی (شاخص مهم برای کاربران فارسی‌زبان)

این مدل با 27.4 میلیارد پارامتر، یکی از مدل‌های سبک‌وزن اما کارآمد گوگل محسوب می‌شود که عملکرد مناسبی در پردازش زبان فارسی (64.3%) دارد.





### **اطلاعات مدل**  
**توضیحات کلی و تعریف مختصر ورودی‌ها و خروجی‌ها:**  

**توضیحات:**  
جما (Gemma) خانواده‌ای از مدل‌های متن‌باز و سبک‌وزن از گوگل است که بر اساس تحقیقات و فناوری مشابه مدل‌های Gemini ساخته شده‌اند. مدل‌های **Gemma 3** چندوجهی (multimodal) هستند و توانایی پردازش ورودی‌های متنی و تصویری را دارند و خروجی متنی تولید می‌کنند. این مدل‌ها در دو نسخه **ازپیش‌آموزش‌دیده** و **تنظیم‌شده برای دستورات** (instruction-tuned) با وزن‌های باز (open weights) ارائه می‌شوند.  

**ویژگی‌های کلیدی Gemma 3:**  
- **پنجره زمینه (context window) بزرگ 128K**  
- **پشتیبانی از چندزبانی (بیش از 140 زبان)**  
- **اندازه‌های متنوع‌تر نسبت به نسخه‌های قبلی**  

**کاربردها:**  
مدل‌های Gemma 3 برای طیف گسترده‌ای از وظایف مانند **پاسخ به سوالات، خلاصه‌نویسی، استدلال و درک تصاویر** مناسب هستند. اندازه نسبتاً کوچک آن‌ها امکان استقرار در محیط‌های با منابع محدود (مانند لپ‌تاپ، کامپیوترهای شخصی یا زیرساخت ابری خصوصی) را فراهم می‌کند. این ویژگی، دسترسی به مدل‌های پیشرفته هوش مصنوعی را **دموکراتیک‌تر** کرده و به نوآوری کمک می‌کند. 

________________________________________






# 3) google/gemma-2-27b-it

•Precision = bfloat16

•Params (B) = 27.2

•Average Accuracy = 65.464

•Part Multiple Choice = 46.03

•ARC Easy = 95.98

•ARC Challenge = 85.91

•MMLU Pro = 36.28

•AUT Multiple Choice Persian = 63.12

### **جدول مشخصات مدل Google/Gemma-2-27B-IT**

| **مشخصه**               | **مقدار**      |
|--------------------------|---------------|
| **نام مدل**             | google/gemma-2-27b-it |
| **دقت محاسباتی**        | bfloat16      |
| **تعداد پارامترها (میلیارد)** | 27.2          |
| **دقت متوسط (Average Accuracy)** | 65.464%       |
| **سوالات چندگزینه‌ای عمومی** | 46.03%        |
| **ARC-Easy**            | 95.98%        |
| **ARC-Challenge**       | 85.91%        |
| **MMLU-Pro**            | 36.28%        |
| **AUT چندگزینه‌ای فارسی** | **63.12%**     |

---

### **توضیحات مختصر معیارها**
- **ARC**: آزمون‌های استدلال علمی (مقادیر بالاتر = بهتر)
- **MMLU**: ارزیابی دانش چندرشته‌ای
- **AUT فارسی**: سنجش عملکرد در زبان فارسی

این مدل نسخه قبلی Gemma-3 با 27.2 میلیارد پارامتر است که در پردازش فارسی 63.12% دقت دارد.




### **اطلاعات مدل**  
**توضیح کلی و تعریف مختصر ورودی‌ها و خروجی‌ها**  

#### **توضیحات**  
**جما (Gemma)** یک خانواده از مدل‌های **سبک‌وزن، پیشرفته و متن‌باز** از گوگل است که با استفاده از تحقیقات و فناوری مشابه مدل‌های **Gemini** توسعه یافته‌اند. این مدل‌ها، **فقط مبتنی بر دیکودر (decoder-only)** بوده و برای **تبدیل متن به متن (text-to-text)** طراحی شده‌اند.  

- **پشتیبانی زبانی:** در حال حاضر فقط **انگلیسی**  
- **انواع مدل:**  
  - **پیش‌آموزش‌دیده (pre-trained)**  
  - **تنظیم‌شده برای دستورات (instruction-tuned)**  
  - **وزن‌های باز (open weights)**  

#### **کاربردها**  
مدل‌های Gemma برای طیف گسترده‌ای از وظایف پردازش زبان طبیعی (NLP) مناسب هستند، از جمله:  
- **پاسخ به سوالات**  
- **خلاصه‌نویسی**  
- **استدلال و تحلیل متن**  

#### **مزیت‌های کلیدی**  
- **اندازه بهینه:** امکان اجرا روی سخت‌افزارهای محدود مانند **لپ‌تاپ، دسکتاپ یا زیرساخت ابری شخصی**  
- **دموکراتیک‌سازی دسترسی:** کمک به گسترش مدل‌های هوش مصنوعی پیشرفته برای همه  
- **تسهیل نوآوری:** مناسب برای توسعه‌دهندگان و محققان  



### **نحوه استفاده**  
در ادامه، نمونه کدهایی برای شروع سریع با این مدل ارائه شده است.  

#### **۱. نصب کتابخانه Transformers**  


#### **۲. انتخاب و اجرای کد مناسب برای کاربرد موردنظر**  
بسته به نیاز خود، می‌توانید از نمونه کدهای موجود در بخش‌های مختلف استفاده کنید.  



**نکته:**  
- مدل‌های Gemma **در حال حاضر فقط از انگلیسی پشتیبانی می‌کنند**.  
- این مدل‌ها **برای پردازش تصویر طراحی نشده‌اند** (برخلاف برخی از مدل‌های Gemini).

 ________________________________________



# 4) Qwen/QwQ-32B-Preview

•Precision = bfloat16

•Params (B) = 32.8

•Average Accuracy = 64.784

•Part Multiple Choice = 46.64

•ARC Easy = 91.95

•ARC Challenge = 87.24

•MMLU Pro = 37.94

•AUT Multiple Choice Persian = 60.15


### **معرفی مدل QwQ-32B-Preview
 یک مدل تحقیقاتی و آزمایشی است که توسط تیم  QwQ-32B-Preview توسعه یافته و بر ارتقای قابلیت‌های استدلال هوش مصنوعی تمرکز دارد. این نسخه پیش‌نمایش، توانایی‌های تحلیلی امیدوارکننده‌ای دارد، اما با محدودیت‌های مهمی همراه است:


#### **محدودیت‌های کلیدی**  
1. **اختلاط زبان و تغییر کد (Code-Switching):**  
   - ممکن است به‌صورت ناخواسته بین زبان‌ها جابه‌جا شود و بر وضوح پاسخ‌ها تأثیر بگذارد.  
   
2. **حلقه‌های استدلالی تکراری:**  
   - احتمال دارد در الگوهای استدلالی چرخشی گیر کند و پاسخ‌های طولانی بدون نتیجه‌گیری مشخص تولید کند.  

3. **ملاحظات امنیتی و اخلاقی:**  
   - نیاز به **تدابیر ایمنی تقویت‌شده** دارد تا عملکردی قابل‌اعتماد و ایمن ارائه دهد.  
   - کاربران باید در زمان استفاده از آن **احتیاط** کنند.  

4. **محدودیت‌های عملکرد و بنچمارک:**  
   - در **ریاضیات و کدنویسی** عملکرد قوی دارد، اما در زمینه‌هایی مانند **استدلال عرفی (Common Sense) و درک ظرافت‌های زبانی** نیاز به بهبود دارد.  



### **مشخصات فنی**  

| ویژگی | مقدار |  
|--------|-------|  
| **نوع مدل** | مدل زبانی علّی (Causal Language Model) |  
| **مراحل آموزش** | پیش‌آموزش (Pretraining) + پس‌آموزش (Post-training) |  
| **معماری** | مبتنی بر **ترنسفورمر** با قابلیت‌های **RoPE، SwiGLU، RMSNorm و Attention QKV bias** |  
| **تعداد پارامترها** | **32.5 میلیارد** |  
| **پارامترهای غیرتعبیه‌ای (Non-Embedding)** | **۳۱.۰ میلیارد** |  
| **تعداد لایه‌ها** | **64** |  
| **تعداد هدهای توجه (GQA)** | **4 برای Q و 8 برای KV** |  
| **طول زمینه (Context Length)** | **32,768 توکن (پشتیبانی کامل)** |  



### **کاربردهای احتمالی**  
- **تحلیل داده‌های پیچیده**  
- **حل مسائل ریاضی و الگوریتمی**  
- **پژوهش در حوزه پردازش زبان طبیعی (NLP)**  

⚠ **هشدار:** این مدل هنوز در مرحله آزمایشی است و برای **استفاده تجاری یا عملیاتی** بدون نظارت دقیق توصیه نمی‌شود.
________________________________________

# 5) Qwen/Qwen2.5-32B-Instruct

•Precision = bfloat16

•Params (B) = 32.8

•Average Accuracy = 64.46

•Part Multiple Choice = 46.06

•ARC Easy = 90.8

•ARC Challenge = 85.91

•MMLU Pro = 38.19

•AUT Multiple Choice Persian = 61.34

### **معرفی مدل‌های Qwen2.5**  
 این مدل جدیدترین سری از مدل‌های زبانی بزرگ (LLM) تیم  Qwen است که در اندازه‌های مختلف از ۰.۵ تا ۷۲ میلیارد پارامتر در دو نسخه پایه (Base) و تنظیم‌شده برای دستورات (Instruction-Tuned) منتشر شده است. این نسخه نسبت به Qwen2 بهبودهای چشمگیری دارد:



### **بهبودهای کلیدی Qwen2.5**  

#### **۱. دانش و عملکرد پیشرفته**  
- افزایش قابل‌توجه **دانش عمومی** و توانایی‌های **کدنویسی و ریاضیات** به لطف استفاده از **مدل‌های متخصص (Expert Models)** در این حوزه‌ها.  

#### **۲. بهبود پیروی از دستورات و پردازش متن‌های طولانی**  
- عملکرد بهتر در:  
  - **تولید متن‌های بلند (بیش از ۸K توکن)**  
  - **درک داده‌های ساختاریافته (مثل جداول)**  
  - **تولید خروجی‌های ساختاریافته (به ویژه JSON)**  
- مقاومت بیشتر در برابر **تنوع دستورات سیستم (System Prompts)** که امکان **اجرای بهتر چت‌بات‌های نقش‌آفرین و تنظیم شرایط پیچیده** را فراهم می‌کند.  

#### **۳. پشتیبانی از زمینه‌های طولانی (Long-Context)**  
- **طول زمینه (Context Length): ۱۲۸K توکن**  
- **تولید متن تا ۸K توکن**  

#### **۴. پشتیبانی چندزبانه**  
- پوشش **۲۹ زبان** از جمله:  
  - **چینی، انگلیسی، فرانسوی، اسپانیایی، پرتغالی، آلمانی، ایتالیایی، روسی**  
  - **ژاپنی، کرهای، ویتنامی، تایلندی، عربی و ...**  

---

### **مشخصات فنی مدل Instruction-Tuned 32B**  

| ویژگی | مقدار |  
|--------|-------|  
| **نوع مدل** | مدل زبانی علّی (Causal Language Model) |  
| **مراحل آموزش** | پیش‌آموزش (Pretraining) + پس‌آموزش (Post-training) |  
| **معماری** | ترنسفورمر با **RoPE، SwiGLU، RMSNorm و Attention QKV bias** |  
| **تعداد پارامترها** | **۳۲.۵ میلیارد** |  
| **پارامترهای غیرتعبیه‌ای** | **۳۱.۰ میلیارد** |  
| **تعداد لایه‌ها** | **۶۴** |  
| **هدهای توجه (GQA)** | **۴۰ برای Q و ۸ برای KV** |  
| **طول زمینه (Context Length)** | **۱۳۱,۰۷۲ توکن (پشتیبانی کامل)** |  
| **حداکثر طول تولید متن** | **۸,۱۹۲ توکن** |  



### **کاربردهای پیشنهادی**  
- **توسعه چت‌بات‌های هوشمند با قابلیت نقش‌آفرینی**  
- **پردازش و تحلیل داده‌های ساختاریافته (JSON، جداول و ...)**  
- **تولید محتوای طولانی (مانند مقالات، گزارش‌ها)**  
- **حل مسائل پیچیده ریاضی و برنامه‌نویسی**  

این مدل **برای استفاده تحقیقاتی و توسعه‌ای** مناسب است و با توجه به پشتیبانی چندزبانه و قابلیت‌های پیشرفته، گزینه‌ای ایده‌آل برای پروژه‌های **NLP چندمنظوره** محسوب می‌شود. 

________________________________________

# 6) google/gemma-2-9b-it

•Precision = bfloat16

•Params (B) = 9.24

•Average Accuracy = 62.886

•Part Multiple Choice = 42.7

•ARC Easy = 93.1

•ARC Challenge = 84.56

•MMLU Pro = 31.74

•AUT Multiple Choice Persian = 62.33


### اطلاعات مدل  
**توضیحات خلاصه و تعریف مختصر ورودی‌ها و خروجی‌ها**  

### توضیحات  
جما (Gemma) خانواده‌ای از مدل‌های متن‌باز سبک‌وزن و پیشرفته از گوگل است که بر پایه تحقیقات و فناوری مشابه مدل‌های جمینی (Gemini) ساخته شده‌اند. این مدل‌ها، مدل‌های زبانی بزرگ با ساختار دیکودر-تنها (decoder-only) هستند که برای تبدیل متن به متن طراحی شده‌اند و در دو نسخه ازپیش‌آموزش‌دیده و تنظیم‌شده برای دستورالعمل‌ها، با وزن‌های (پارامترهای) متن‌باز در دسترس قرار گرفته‌اند. مدل‌های جما برای کاربردهای مختلف تولید متن مانند پاسخ به پرسش‌ها، خلاصه‌نویسی و استدلال مناسب هستند. اندازه نسبتاً کوچک این مدل‌ها، امکان استقرار آن‌ها در محیط‌هایی با منابع محدود مانند لپ‌تاپ، رایانه‌های شخصی یا زیرساخت ابری اختصاصی را فراهم می‌کند. این ویژگی، دسترسی به مدل‌های هوش مصنوعی پیشرفته را برای همگان دموکراتیک می‌کند و به پرورش نوآوری کمک می‌نماید.  

________________________________________






# 7) CohereLabs/aya-expanse-32b

•Precision = float16

•Params (B) = 32.3

•Average Accuracy = 61.938

•Part Multiple Choice = 43.36

•ARC Easy = 93.1

•ARC Challenge = 79.87

•MMLU Pro = 31.03

•AUT Multiple Choice Persian = 62.33




### **Aya Expanse 32B**  

**مدل تحقیقاتی با وزن‌های باز و قابلیت‌های چندزبانه پیشرفته**  

**Aya Expanse 32B** یک مدل زبانی بزرگ چندزبانه با وزن‌های باز است که نتیجه ترکیب مدل‌های **Command** (از خانواده مدل‌های پرکاربرد) با یک سال پژوهش تخصصی **Cohere Labs** در زمینه‌های زیر است:  
- **انتخاب و بهینه‌سازی داده‌ها (Data Arbitrage)**  
- **آموزش ترجیحی چندزبانه (Multilingual Preference Training)**  
- **تنظیم ایمنی (Safety Tuning)**  
- **ادغام مدل‌ها (Model Merging)**  

این مدل قدرتمند از **23 زبان** پشتیبانی می‌کند و برای تحقیقات و کاربردهای چندزبانه طراحی شده است.  



### **مشخصات مدل**  
- **توسعه‌دهنده:** Cohere Labs  
- **نقطه تماس:** تیم Cohere Labs  
- **مجوز:** CC-BY-NC (مشروط به رعایت **سیاست استفاده قابل قبول Cohere Labs**)  
- **نام مدل:** Aya Expanse 32B  
- **اندازه مدل:** 32 میلیارد پارامتر  



### **نسخه‌های موجود**  
این مدل‌کارد مربوط به نسخه **32 میلیارد پارامتری** است. یک نسخه **8 میلیارد پارامتری** نیز منتشر شده 



### **زبان‌های پشتیبانی‌شده**  
این مدل از **۲۳ زبان** پشتیبانی می‌کند:  
- عربی  
- چینی (ساده‌شده و سنتی)  
- چکی  
- هلندی  
- انگلیسی  
- فرانسوی  
- آلمانی  
- یونانی  
- عبری  
- هندی  
- اندونزیایی  
- ایتالیایی  
- ژاپنی  
- کره‌ای  
- فارسی  
- لهستانی  
- پرتغالی  
- رومانیایی  
- روسی  
- اسپانیایی  
- ترکی استانبولی  
- اوکراینی  
- ویتنامی  

این مدل برای تسهیل تحقیقات و توسعه در حوزه پردازش زبان‌های طبیعی (NLP) با تمرکز بر چندزبانی طراحی شده است.
________________________________________


# 8)  CohereLabs/aya-expanse-8b

•Precision = float16

•Params (B) = 8.03

•Average Accuracy = 53.684

•Part Multiple Choice = 34.91

•ARC Easy = 79.6

•ARC Challenge = 70.47

•MMLU Pro = 25.06

•AUT Multiple Choice Persian = 58.38




### **Aya Expanse 8B**  
**یک مدل زبانی چندزبانه پیشرفته با وزن‌های باز (open-weight) برای تحقیقات**  



### **معرفی مدل**  
**Aya Expanse 8B** یک مدل زبانی بزرگ (LLM) است که با تمرکز بر **توانایی‌های چندزبانه پیشرفته** توسعه یافته است. این مدل ترکیبی از:  
- **مدل‌های از پیش آموزش‌دیده خانواده Command** (با عملکرد بالا)  
- **یک سال تحقیق اختصاصی تیم Cohere Labs** در زمینه‌های:  
  - **داوری داده (Data Arbitrage)**  
  - **آموزش ترجیح چندزبانه (Multilingual Preference Training)**  
  - **تنظیم ایمنی (Safety Tuning)**  
  - **ادغام مدل‌ها (Model Merging)**  

**نسخه ۸ میلیارد پارامتری (8B)** این مدل منتشر شده است و یک **نسخه ۳۲ میلیاردی (32B)** نیز در دسترس می‌باشد.  



### **مشخصات فنی**  
- **توسعه‌دهنده:** **Cohere Labs**  
- **تماس:** از طریق تیم **Cohere Labs**  
- **مجوز:** **CC-BY-NC** (غیرتجاری) + رعایت **سیاست استفاده قابل قبول Cohere Labs**  
- **نام مدل:** **Aya Expanse 8B**  
- **اندازه مدل:** **۸ میلیارد پارامتر**  



### **زبان‌های پشتیبانی شده**  
این مدل از **۲۳ زبان** پشتیبانی می‌کند، شامل:  
- **عربی**  
- **چینی (ساده‌شده و سنتی)**  
- **چکی**  
- **هلندی**  
- **انگلیسی**  
- **فرانسوی**  
- **آلمانی**  
- **یونانی**  
- **عبری**  
- **هندی**  
- **اندونزیایی**  
- **ایتالیایی**  
- **ژاپنی**  
- **کره‌ای**  
- **فارسی**  
- **لهستانی**  
- **پرتغالی**  
- **رومانیایی**  
- **روسی**  
- **اسپانیایی**  
- **ترکی**  
- **اوکراینی**  
- **ویتنامی**  



### **ویژگی‌های کلیدی**  
✅ **چندزبانه پیشرفته** (پشتیبانی از ۲۳ زبان)  
✅ **بهینه‌شده برای ایمنی و ترجیحات چندزبانه**  
✅ **ترکیب تکنیک‌های پیشرفته یادگیری ماشین**  
✅ **مناسب برای تحقیقات و کاربردهای غیرتجاری**  



### **لینک‌های مرتبط**  
- **نسخه ۳۲ میلیاردی (32B)** 
- **سیاست استفاده قابل قبول Cohere Labs**  


🔹 **این مدل برای استفاده تحقیقاتی و با مجوز غیرتجاری منتشر شده است.**




________________________________________


# 9) Qwen/Qwen2.5-7B-Instruct

•Precision = bfloat16

•Params (B) = 7.62

•Average Accuracy = 51.898

•Part Multiple Choice = 36.72

•ARC Easy = 79.02

•ARC Challenge = 69.13

•MMLU Pro = 21.96

•AUT Multiple Choice Persian = 52.66


### **معرفی**  

در مقایسه با مدل‌های زبان **منبع‌باز (open-source)** پیشرو، از جمله **Qwen1.5** که پیش‌تر منتشر شد، **Qwen2** به‌طور کلی از بیشتر مدل‌های منبع‌باز پیشی گرفته و در مقایسه با مدل‌های انحصاری **(proprietary)** در مجموعه‌ای از معیارهای ارزیابی، شامل:  
- **درک زبان**  
- **تولید زبان**  
- **توانایی چندزبانه**  
- **کدنویسی**  
- **ریاضیات**  
- **استدلال**  
رقابت‌پذیری بالایی نشان داده است.  
  



### **جزئیات مدل**  
   این مدل یک سری از مدل‌های زبانی مبتنی بر **معماری Transformer** است که شامل ویژگی‌های زیر می‌شود:  
- **فعال‌سازی SwiGLU**  
- **بایاس QKV توجه (Attention QKV Bias)**  
- **توجه پرس‌وجوی گروهی (Group Query Attention)**  

برای هر اندازه مدل، دو نسخه منتشر شده است:  
1. **مدل پایه (Base Language Model)**  
2. **مدل چت هماهنگ‌شده (Aligned Chat Model)**  



### **جزئیات آموزش**  
- **پیش‌آموزش (Pretraining):** با حجم عظیمی از داده‌ها انجام شده است.  
- **پس‌آموزش (Post-training):** شامل **تنظیم دقیق نظارت‌شده (Supervised Finetuning)** و **بهینه‌سازی ترجیح مستقیم (Direct Preference Optimization - DPO)** است.  

این مدل‌ها برای کاربردهای **چندمنظوره**، از جمله **پردازش زبان طبیعی (NLP)**، **تولید کد**، و **محاسبات پیچیده** بهینه‌سازی شده‌اند.  

________________________________________




# 10) Qwen/Qwen2-7B-Instruct

•Precision = bfloat16

•Params (B) = 7.62

•Average Accuracy = 51.442

•Part Multiple Choice = 35.9

•ARC Easy = 77.3

•ARC Challenge = 68.46

•MMLU Pro = 23.87

•AUT Multiple Choice Persian = 51.68


























